{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pitthexai/IEEE_BHI_2023_Tutorial_From_Few_to_None/blob/main/Code/FewShotSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTYVyaNi8-V_"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch import utils as smp_utils\n",
        "\n",
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "rOe1s38U9DjE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/pitthexai/IEEE_BHI_2023_Tutorial_From_Few_to_None/raw/bcce5fd52b349659fb03fd065f9037e70acc83a9/SampleDataset/BHI_Segmentation.zip\n",
        "! unzip /content/BHI_Segmentation.zip"
      ],
      "metadata": {
        "id": "7Drx1f2R95V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/content/BHI_Segmentation\"\n",
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "hX9-JbPk99-T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JointSpaceSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, image_files, mask_files, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.img_files = image_files\n",
        "        self.mask_files = mask_files\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(os.path.join(self.img_root, self.img_files[idx])))\n",
        "        mask = np.array(Image.open(os.path.join(self.mask_root, self.mask_files[idx])))\n",
        "\n",
        "        # image = np.stack([image, image, image], axis=0)\n",
        "        # mask = np.expand_dims(mask, axis=0)\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        mask = torch.unsqueeze(mask, 0)\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "        return image.type(torch.FloatTensor), mask/255.0"
      ],
      "metadata": {
        "id": "kEEdc-Bb-IR_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def generate_datasets(root_dir):\n",
        "    x_dir = os.path.join(root_dir, \"Images\")\n",
        "    y_dir = os.path.join(root_dir, \"Annotations\")\n",
        "    records = [[img.split(\".\")[0][:-1], img, img] for img in os.listdir(x_dir)]\n",
        "\n",
        "    data_records = pd.DataFrame(records, columns=[\"pid\", \"images\", \"masks\"])\n",
        "\n",
        "    train, test = train_test_split(data_records.pid.unique(), test_size=0.5, random_state=RANDOM_STATE)\n",
        "    valid, test = train_test_split(test, test_size=0.5, random_state=RANDOM_STATE)\n",
        "\n",
        "    train = data_records[data_records.pid.isin(train)].reset_index(drop=True)\n",
        "    valid = data_records[data_records.pid.isin(valid)].reset_index(drop=True)\n",
        "    test = data_records[data_records.pid.isin(test)].reset_index(drop=True)\n",
        "\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "WoPnHYmVAUOj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_few_shot_sample(dataset, k=1, random_state=RANDOM_STATE):\n",
        "    if k > len(dataset):\n",
        "        return dataset\n",
        "\n",
        "    return dataset.sample(k, random_state=random_state).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5ycmpD7rAd5v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = generate_datasets(os.path.join(DATA_ROOT))"
      ],
      "metadata": {
        "id": "ozHTHTWrAtbh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_few = get_few_shot_sample(train, k=5)\n",
        "valid_few = get_few_shot_sample(valid, k=5)"
      ],
      "metadata": {
        "id": "xZNFQ-_gAzNZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessing_fn(encoder, encoder_weights):\n",
        "    return smp.encoders.get_preprocessing_fn(encoder, encoder_weights)\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "\n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ],
      "metadata": {
        "id": "BiVsrVj0A3Ut"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = \"resnet34\"\n",
        "encoder_weights = \"imagenet\"\n",
        "activation = \"sigmoid\"\n",
        "num_classes = 1 # 0=background, 1=joint space\n",
        "\n",
        "preprocessing_fn = get_preprocessing_fn(encoder, encoder_weights)\n",
        "augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()])"
      ],
      "metadata": {
        "id": "y7TDc-gQA53Z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = JointSpaceSegmentationDataset(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                          os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                          train_few.images, train_few.masks,\n",
        "                                          preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                          transforms=augmentations)\n",
        "\n",
        "valid_set = JointSpaceSegmentationDataset(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                          os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                          valid_few.images, valid_few.masks,\n",
        "                                          preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                          transforms=augmentations)\n",
        "\n",
        "test_set = JointSpaceSegmentationDataset(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                         os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                         test.images, test.masks,\n",
        "                                         preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                         transforms=augmentations)"
      ],
      "metadata": {
        "id": "0ajiW_Z_A7j1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "model = copy.deepcopy(smp.Unet(encoder_name=encoder, encoder_weights=encoder_weights, in_channels=1,\n",
        "                 classes=num_classes, activation=activation))\n",
        "model.encoder.requires_grad_ = True\n",
        "loss = nn.BCELoss()\n",
        "loss.__name__=\"loss\"\n",
        "metrics = [smp_utils.metrics.IoU(threshold=0.5), smp_utils.metrics.Fscore(0.5)]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-04)"
      ],
      "metadata": {
        "id": "h4Y5Bu1dBK89"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=1, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=1, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "RUfI5BGfBNBZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create epoch runners\n",
        "# it is a simple loop of iterating over dataloader`s samples\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=\"cpu\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=\"cpu\",\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "FiR3PLn5BrvN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model for 40 epochs\n",
        "\n",
        "max_score = 0\n",
        "\n",
        "for i in range(1, 50):\n",
        "\n",
        "    print('\\nEpoch: {}'.format(i))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(valid_loader)\n",
        "\n",
        "    # do something (save model, change lr, etc.)\n",
        "    if max_score < valid_logs['iou_score']:\n",
        "        max_score = valid_logs['iou_score']\n",
        "        torch.save(model, './best_model.pth')\n",
        "        print('Model saved!')\n"
      ],
      "metadata": {
        "id": "UJmmgjkvBtMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
        "test_img, test_mask  = next(iter(test_loader))"
      ],
      "metadata": {
        "id": "KfnwCPLjByYM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_iou = 0.0\n",
        "avg_fscore = 0.0\n",
        "iou_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
        "fscore_metric = smp.utils.metrics.Fscore(threshold=0.5)\n",
        "for img, mask in test_loader:\n",
        "    out = model(img)\n",
        "    mask = mask\n",
        "    avg_iou += iou_metric(out, mask).item()\n",
        "    avg_fscore += fscore_metric(out, mask).item()\n",
        "\n",
        "print(avg_iou/len(test_loader), avg_fscore/len(test_loader))"
      ],
      "metadata": {
        "id": "BUF9MpsTDOIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zww2RkqHDQKq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}